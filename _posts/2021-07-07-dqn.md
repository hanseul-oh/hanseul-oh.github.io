---
title: DQN
excerpt: 강화학습을 해보자

categories:
  - Reinforcement Learning
tags:
  - [Reinforcement Learning]

toc: ture
toc_stcky: true
---

강화학습이란 무엇인가?
주어진 조건에서 어떤 동작을 취해야 할지 결정하는 문제들을 제어과제라 부른다. 예를 들어 레이싱 게임에서 직선주로에서 코너구간으로 넘어가는 상황(주어진 조건)에서 속도를 줄이면서 핸들의 방향을 돌리는(어떤 동작을 취하는지) 행동을 취한다던지, 주식시장이 좋거나 나쁠 때 어떤 종목을 매수하고 매도를 할 것인지 결정할 때와 같은 상황들을 말한다.
강화학습은 이러한 제어 과제의 표현 및 해결을 위한 일반적인 틀이다.

그럼 바로 cartpole문제에 강화학습을 적용시켜 보자
cartpole문제는 좌우로 이동할 수 있는 cart(검은 나무상자)에 나무막대가 서 있어서 이 나무막대가 쓰러지지 않게 cart를 좌우로 움직이게 하는 것이다.
cartpole에 강화학습을 적용하기 위해 먼저 조건과 행동을 설정해야한다. 이를 위해 gym이라는 라이브러리를 사용할 것이다.
gym을 이용하면 조건과 행동이 모두 갖춰줘 있기 때문에 따로 설정할 필요가 없다. 

Cartpole문제는 네모난 검은색 박스 위에 막대기가 올려져 있고 이 박스를 오른쪽 또는 왼쪽으로 움직여서  
![cartpole_random](https://user-images.githubusercontent.com/55029184/150935845-b44d7cfd-e559-47fb-8341-d1561a52be43.gif)

학습과정의 차이
지도학습에서 이미지 분류를 보면 모형에 분류가 완료된 데이터를 학습시킨다. 반면 강화학습은 탐험(무작위)을 통해 내가 행한 행동이 어떤 결과를 가져다 주는지에 기반하여 학습 데이터가 만들어진다.
cartpole을 예를 든다면 막대가 오른쪽으로 기울어져 있을 때, cart를 오른쪽으로 밀어 막대가 기울어진 정도를 줄인다면 좋은 결과를 가져다주므로 이 행동에 대한 가치를 더 높여주고 cart를 왼쪽으로 밀어서 막대의 기울어진 정도가 더 커졌다면 나쁜 결과를 가져다주므로 이 행동에 대한 가치를 감소시켜서 만들어진 데이터를 모형에 학습시킨다.
그럼 모형은 주어진 각 상황에서 기존의 각 행동에 대한 가치값과 수정된 가치값의 비교를 통해 더 높은 가치를 지닌 행동에 대해 가중치를 업데이트 해갈 것이다.


이미지 분류나 값을 예측하고자 하는 회귀
강화학습은 탐험을 통해 학습데이터를 만든다.


위에서 언급했듯 제어과제는 주어진 조건에서 어떤 동작을 취해야 할지 결정하는 것이고 cartpole에  문제에서 조건과 행동을 설정해야한다.

위에서 언급했듯 주어진 조건에서 어떤 동작을 취해야 할지 결정하는 문제를 해결하고자 한다. 

참고로 cartpole 문제는 gym에서 두 가지 버전이 있다. CartPole-v0.
gym.envs.registry.all()


오른쪽 or 왼쪽 두 가지 행동 중의 하나를 택하는데 랜덤으로 이 행동을 할 때 어떤 결과를 가져다 주는지 보자
<script src="https://gist.github.com/hanseul-oh/d5003ba9843cb6075900f3260ba97ab5.js"></script>





